<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=MacRoman">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchReview = true;	// search in review

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchReview && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchReview=!searchReview;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchReview){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; margin: auto 2em; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { width: 100%; empty-cells: show; border-spacing: 0em 0.2em; margin: 1em 0em; border-style: none; }
th, td { border: 1px gray solid; border-width: 1px 1px; padding: 0.5em; vertical-align: top; text-align: left; }
th { background-color: #efefef; }
td + td, th + th { border-left: none; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom: 1px gray solid; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>

<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include review</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<thead><tr><th width="20%">Author</th><th width="30%">Title</th><th width="5%">Year</th><th width="30%">Journal/Proceedings</th><th width="10%">Reftype</th><th width="5%">DOI/URL</th></tr></thead>
<tbody><tr id="Ang2008" class="entry">
	<td>Ang, M.H.</td>
	<td>Robotics: The New Emerging Applications <p class="infolinks">[<a href="javascript:toggleInfo('Ang2008','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ang2008','bibtex')">BibTeX</a>]</p></td>
	<td>2008</td>
	<td><br/>Vol. 02008 Second Asia International Conference on Modelling Simulation AMS, pp. xxiv-xxiv&nbsp;</td>
	<td>misc</td>
	<td><a href="http://dx.doi.org/10.1109/AMS.2008.190">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Ang2008" class="abstract show">
	<td colspan="6"><b>Abstract</b>: The discipline of robotics has emerged from developments in industrial robots where precision is of primary importance. Robotics research continues to contribute to the creation of objects and robotic systems that improve the quality of our lives. However, the body of knowledge generated in robotics is making an impact beyond robot applications. Recent developments coupled with advancement of computing technology facilitated the application of robotics knowledge to create robotic systems that can operate in unstructured environments occupied by humans, providing service and assisting humans. Furthermore, robotics as a science is being applied and contributing to the development of other disciplines not traditionally associated with robotics. These include computer graphics and animation towards realistic physical simulations of motions and interactions of moving bodies as they collide and interact with each other. Other applications include the study of motion-based behaviors of biological/organic materials including humans. The development of dynamic models of articulated bodies is central for achieving realistic motions and for the design of effective controllers with the needed performance in motions and interactions. These models are especially useful in simulation environments. At the same time, advancements in biology and other disciplines are having a significant influence on the developments in robotics. This synergy between robotics and emerging applications is resulting, for example, in biomimetic robotic systems with mechanical designs closer to biological beings and their learning capabilities. In this presentation, we will discuss models and algorithms in robotics and highlight examples showing their diverse applications.</td>
</tr>
<tr id="bib_Ang2008" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Ang2008,
  author = {Ang, M H},
  title = {Robotics: The New Emerging Applications},
  booktitle = {2008 Second Asia International Conference on Modelling Simulation AMS},
  publisher = {IEEE Computer Society},
  year = {2008},
  volume = {0},
  pages = {xxiv--xxiv},
  doi = {http://dx.doi.org/10.1109/AMS.2008.190}
}
</pre></td>
</tr>
<tr id="Bar-Cohen2006" class="entry">
	<td>Bar-Cohen, Y.</td>
	<td>Biomimetics--using nature to inspire human innovation. <p class="infolinks">[<a href="javascript:toggleInfo('Bar-Cohen2006','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bar-Cohen2006','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>Bioinspiration biomimetics<br/>Vol. 1(1), pp. P1-P12&nbsp;</td>
	<td>article</td>
	<td><a href="http://www.ncbi.nlm.nih.gov/pubmed/17671297">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bar-Cohen2006" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Evolution has resolved many of nature's challenges leading to lasting solutions. Nature has always inspired human achievements and has led to effective materials, structures, tools, mechanisms, processes, algorithms, methods, systems, and many other benefits (Bar-Cohen Y (ed) 2005 Biomimetics-Biologically Inspired Technologies (Boca Raton, FL: CRC Press) pp 1-552). This field, which is known as biomimetics, offers enormous potential for inspiring new capabilities for exciting future technologies. There are numerous examples of biomimetic successes that involve making simple copies, such as the use of fins for swimming. Others examples involved greater mimicking complexity including the mastery of flying that became possible only after the principles of aerodynamics were better understood. Some commercial implementations of biomimetics, including robotic toys and movie subjects, are increasingly appearing and behaving like living creatures. More substantial benefits of biomimetics include the development of prosthetics that closely mimic real limbs and sensory-enhancing microchips that are interfaced with the brain to assist in hearing, seeing and controlling instruments. A review is given of selected areas that were inspired by nature, and an outlook for potential development in biomimetics is presented.</td>
</tr>
<tr id="bib_Bar-Cohen2006" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bar-Cohen2006,
  author = {Bar-Cohen, Yoseph},
  title = {Biomimetics--using nature to inspire human innovation.},
  journal = {Bioinspiration biomimetics},
  year = {2006},
  volume = {1},
  number = {1},
  pages = {P1--P12},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/17671297}
}
</pre></td>
</tr>
<tr id="Bar-Cohen2006a" class="entry">
	<td>Bar-Cohen, Y.</td>
	<td>Biomimetics: biologically inspired technologies <p class="infolinks">[<a href="javascript:toggleInfo('Bar-Cohen2006a','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bar-Cohen2006a','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>Materials Today<br/>Vol. 9(3), pp. 56&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S1369-7021(06)71400-6">DOI</a> <a href="http://linkinghub.elsevier.com/retrieve/pii/S1369702106714006">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bar-Cohen2006a" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Nature is the world's foremost designer. With billions of years of experience and boasting the most extensive laboratory available, it conducts research in every branch of engineering and science. Nature's designs and capabilities have always inspired technology, from the use of tongs and tweezers to genetic algorithms and autonomous legged robots. Taking a systems perspective rather than focusing narrowly on materials or chemistry aspects, Biomimetics: Biologically Inspired Technologies examines the field from every angle. The book contains pioneering approaches to biomimetics including a new perspective on the mechanization of cognition and intelligence, as well as defense and attack strategies in nature, their applications, and potential. It surveys the field from modeling to applications and from nano- to macro-scales, beginning with an introduction to principles of using biology to inspire designs as well as biological mechanisms as models for technology. This innovative guide discusses evolutionary robotics; genetic algorithms; molecular machines; multifunctional, biological-, and nano- materials; nastic structures inspired by plants; and functional surfaces in biology. Looking inward at biological systems, the book covers the topics of biomimetic materials, structures, control, cognition, artificial muscles, biosensors that mimic senses, artificial organs, and interfaces between engineered and biological systems. The final chapter contemplates the future of the field and outlines the challenges ahead. Featuring extensive illustrations, including a 32-page full-color insert, Biomimetics: Biologically Inspired Technologies provides unmatched breadth of scope as well as lucid illumination of this promising field.</td>
</tr>
<tr id="bib_Bar-Cohen2006a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bar-Cohen2006a,
  author = {Bar-Cohen, Yoseph},
  title = {Biomimetics: biologically inspired technologies},
  journal = {Materials Today},
  publisher = {CRC Press},
  year = {2006},
  volume = {9},
  number = {3},
  pages = {56},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1369702106714006},
  doi = {http://dx.doi.org/10.1016/S1369-7021(06)71400-6}
}
</pre></td>
</tr>
<tr id="Bar-Cohen2003" class="entry">
	<td>Bar-Cohen, Y.</td>
	<td>Biologically inspired intelligent robots using artificial muscles <p class="infolinks">[<a href="javascript:toggleInfo('Bar-Cohen2003','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bar-Cohen2003','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td><br/>Vol. 41(1)Proceedings International Conference on MEMS NANO and Smart Systems, pp. 19-24&nbsp;</td>
	<td>misc</td>
	<td><a href="http://dx.doi.org/10.1109/ICMENS.2003.1221956">DOI</a> <a href="http://doi.wiley.com/10.1111/j.1475-1305.2004.00161.x">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bar-Cohen2003" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Humans throughout history have always sought to mimic the appearance, mobility, functionality, intelligent operation, and thinking process of biological creatures. This field of biologically inspired technology, having the moniker biomimetics, has evolved from making static copies of human and animals in the form of statues to the emergence of robots that operate with realistic appearance and behavior. Technology evolution led to such fields as artificial muscles, artificial intelligence, artificial vision and biomimetic capabilities in materials science, mechanics, electronics, computing science, information technology and many others. One of the newest fields is the artificial muscles, which is the moniker for electroactive polymers (EAP). Efforts are made worldwide to establish a strong infrastructure for this actuation materials ranging from analytical modeling and comprehensive understanding of their response mechanism to effective processing and characterization techniques. The field is still in its emerging state and robust materials are still not readily available however in recent years significant progress has been made. To promote faster advancement in the field, in 1999, the author posed a challenge to the research and engineering community to develop a robotic arm that would wrestle against human opponent and win. Currently, he is considering setting up the first competition in 2005. This paper covers the current state-of-the-art and challenges to making biomimetic robots using artificial muscles.</td>
</tr>
<tr id="bib_Bar-Cohen2003" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Bar-Cohen2003,
  author = {Bar-Cohen, Y},
  title = {Biologically inspired intelligent robots using artificial muscles},
  booktitle = {Proceedings International Conference on MEMS NANO and Smart Systems},
  publisher = {Wiley Online Library},
  year = {2003},
  volume = {41},
  number = {1},
  pages = {19--24},
  url = {http://doi.wiley.com/10.1111/j.1475-1305.2004.00161.x},
  doi = {http://dx.doi.org/10.1109/ICMENS.2003.1221956}
}
</pre></td>
</tr>
<tr id="Bar-cohen2003" class="entry">
	<td>Bar-cohen, Y. and Breazeal, C.</td>
	<td>Biologically inspired intelligent robots <p class="infolinks">[<a href="javascript:toggleInfo('Bar-cohen2003','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bar-cohen2003','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td>Jet Propulsion<br/>Vol. 5051(1), pp. 1-7&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1117/12.484379">DOI</a> <a href="http://link.aip.org/link/?PSI/5051/14/1\&Agg=doi">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bar-cohen2003" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Humansthroughout history have always sought to mimic the appearance, mobility,functionality, intelligent operation, and thinking process of biological creatures. This field of biologically inspired technology, having the moniker biomimetics,has evolved from making static copies of human and animalsin the form of statues to the emergence of robotsthat operate with realistic behavior. Imagine a person walkingtowards you where suddenly you notice something weird about him-heis not real but rather he is a robot. Your reaction would probably be "I can't believe it butthis robot looks very real" just as you would reactto an artificial flower that is a good imitation. You may even proceed and touch the robot to checkif your assessment is correct but, as oppose to theflower case, the robot may be programmed to respond physicaland verbally. This science fiction scenario could become areality as the current trend continues in developing biologically inspiredtechnologies. Technology evolution led to such fields as artificialmuscles, artificial intelligence, and artificial vision as well as biomimeticcapabilities in materials science, mechanics, electronics, computing science, information technologyand many others. This paper will review the stateof the art and challenges to biologically-inspired technologies and therole that EAP is expected to play as the technologyevolves. 2003 COPYRIGHT SPIE-The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.</td>
</tr>
<tr id="bib_Bar-cohen2003" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bar-cohen2003,
  author = {Bar-cohen, Yoseph and Breazeal, Cynthia},
  title = {Biologically inspired intelligent robots},
  journal = {Jet Propulsion},
  publisher = {SPIE},
  year = {2003},
  volume = {5051},
  number = {1},
  pages = {1--7},
  url = {http://link.aip.org/link/?PSI/5051/14/1&amp;Agg=doi},
  doi = {http://dx.doi.org/10.1117/12.484379}
}
</pre></td>
</tr>
<tr id="Beer1997" class="entry">
	<td>Beer, R.D., Quinn, R.D., Chiel, H.J. and Ritzmann, R.E.</td>
	<td>Biologically inspired approaches to robotics: what can we learn from insects? <p class="infolinks">[<a href="javascript:toggleInfo('Beer1997','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Beer1997','bibtex')">BibTeX</a>]</p></td>
	<td>1997</td>
	<td>Communications of the ACM<br/>Vol. 40(3), pp. 30-38&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1145/245108.245118">DOI</a> <a href="http://portal.acm.org/citation.cfm?doid=245108.245118">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Beer1997" class="abstract show">
	<td colspan="6"><b>Abstract</b>: When it comes to autonomous robots, the contrast between fantasy and reality is really quite striking. On the one hand, we have the fantasy of such anthropomorphic robots as C3PO from Star Wars and Commander Data from Star Trek: The Next Generation which, despite their endearing quirks, negotiate complex physical and social environments with essentially the skill of a human being. On the other hand, we have the reality of industrial robots that can efficiently carry out such highly specialized tasks as painting and welding only in environments carefully constrained to minimize complications. Or, to consider a second example, we have Dante II, the semi-autonomous robot that had to be lifted out of a volcano it was exploring with a crane when it overturned. Far from being a limitation unique to the Dante II project, which should be applauded for confronting such a difficult environment, this brittleness in the face of unanticipated contingency is in fact typical of the state of the art in autonomous robotics.</td>
</tr>
<tr id="bib_Beer1997" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Beer1997,
  author = {Beer, Randall D and Quinn, Roger D and Chiel, Hillel J and Ritzmann, Roy E},
  title = {Biologically inspired approaches to robotics: what can we learn from insects?},
  journal = {Communications of the ACM},
  publisher = {ACM},
  year = {1997},
  volume = {40},
  number = {3},
  pages = {30--38},
  url = {http://portal.acm.org/citation.cfm?doid=245108.245118},
  doi = {http://dx.doi.org/10.1145/245108.245118}
}
</pre></td>
</tr>
<tr id="Breazeal2005" class="entry">
	<td>Breazeal, C.</td>
	<td>Socially intelligent robots <p class="infolinks">[<a href="javascript:toggleInfo('Breazeal2005','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Breazeal2005','bibtex')">BibTeX</a>]</p></td>
	<td>2005</td>
	<td>interactions<br/>Vol. 12(2), pp. 22&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1145/1052438.1052455">DOI</a> <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed\&cmd=Retrieve\&dopt=AbstractPlus\&list\_uids=665834043048906300related:PM5Kz4iEPQkJ">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Breazeal2005" class="abstract show">
	<td colspan="6"><b>Abstract</b>: . Cynthia Breazeal. Table of Contents. are interesting from a scientific perspective as well.</td>
</tr>
<tr id="bib_Breazeal2005" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Breazeal2005,
  author = {Breazeal, C},
  title = {Socially intelligent robots},
  journal = {interactions},
  publisher = {ACM},
  year = {2005},
  volume = {12},
  number = {2},
  pages = {22},
  url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed&amp;cmd=Retrieve&amp;dopt=AbstractPlus&amp;listuids=665834043048906300related:PM5Kz4iEPQkJ},
  doi = {http://dx.doi.org/10.1145/1052438.1052455}
}
</pre></td>
</tr>
<tr id="Gage2012" class="entry">
	<td>Gage, F.H. and Muotri, A.R.</td>
	<td>Neuroscience: The Human Brain project <p class="infolinks">[<a href="javascript:toggleInfo('Gage2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gage2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Scientific American<br/>Vol. 306(3), pp. 50-55&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Gage2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Building a vast digital simulation of the brain could transform neuroscience and medicine and reveal new ways of making more powerful computers.</td>
</tr>
<tr id="bib_Gage2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Gage2012,
  author = {Gage, F H and Muotri, A R},
  title = {Neuroscience: The Human Brain project},
  journal = {Scientific American},
  year = {2012},
  volume = {306},
  number = {3},
  pages = {50--55}
}
</pre></td>
</tr>
<tr id="Hengel2012" class="entry">
	<td>Hengel, U.V.</td>
	<td>A neural-dynamic architecture for flexible spatial language: intrinsic frames, the term “between”, and autonomy <p class="infolinks">[<a href="javascript:toggleInfo('Hengel2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hengel2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>RO-MAN, 2012 ldots&nbsp;</td>
	<td>article</td>
	<td><a href="http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6343746">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Hengel2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Spatial language is a privileged channel of human- robot interaction. We extend a neural-dynamic architecture for grounded spatial language in three ways: First, viewer- centered vs. intrinsic reference frames may be autonomously selected. Using intrinsic reference frames requires estimation of the orientation of the reference object. Second, we employ a similar orientation estimation to enable the use of configurations of reference objects for spatial terms such as “between”. Third, we enhance the autonomy of the system so that the required sequence of attentional shifts, coordinate transforms, and selection decisions emerges from the time-continuous neural dynamics. By implementing the approach in a robotic setting we demonstrate that simple feature information obtained from video cameras is sufficient to ground spatial language.</td>
</tr>
<tr id="bib_Hengel2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hengel2012,
  author = {Hengel, Ulja Van},
  title = {A neural-dynamic architecture for flexible spatial language: intrinsic frames, the term “between”, and autonomy},
  journal = {RO-MAN, 2012 ldots},
  year = {2012},
  url = {http://ieeexplore.ieee.org/xpls/absall.jsp?arnumber=6343746}
}
</pre></td>
</tr>
<tr id="Hosoda2011" class="entry">
	<td>Hosoda, K.</td>
	<td>Robust Haptic Recognition by Anthropomorphic Bionic Hand through Dynamic Interaction <p class="infolinks">[<a href="javascript:toggleInfo('Hosoda2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hosoda2011','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>IEEE International Conference on Intelligent Robots and Systems, pp. 1236-1241&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Hosoda2011" class="abstract show">
	<td colspan="6"><b>Abstract</b>: This paper describes learning of robust haptic recognition by Bionic Hand, a human-like robot hand, through dynamic interaction with the object. Bionic hand is a humanlike hand that has soft skin with distributed receptors and is driven by artiﬁcial pneumatic muscles. At the beginning of learning, it utilizes the result of physical interaction with the object: thanks to the hand compliance, regrasping will leads object’s posture to stable one in the hand. This result can be successively used as object classiﬁcation for learning dynamic interaction between the hand and the object by a recurrent neural network. We conduct experiments and show that the proposed method is effective for robust and fast object recognition.</td>
</tr>
<tr id="bib_Hosoda2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Hosoda2011,
  author = {Hosoda, K},
  title = {Robust Haptic Recognition by Anthropomorphic Bionic Hand through Dynamic Interaction},
  booktitle = {IEEE International Conference on Intelligent Robots and Systems},
  publisher = {Cambridge University Press},
  year = {2010},
  pages = {1236--1241}
}
</pre></td>
</tr>
<tr id="Hourdakis2007" class="entry">
	<td>Hourdakis, E., Maniadakis, M. and Trahanias, P.</td>
	<td>A biologically inspired approach for the control of the hand <p class="infolinks">[<a href="javascript:toggleInfo('Hourdakis2007','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hourdakis2007','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>2007 IEEE Congress on Evolutionary Computation, pp. 1503-1510&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/CEC.2007.4424650">DOI</a> <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4424650">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Hourdakis2007" class="abstract show">
	<td colspan="6"><b>Abstract</b>: The control of the hand in primate species is characterized by a high dimensionality, due to the large number of joints in the fingers. In this study we present how its manipulation can be simplified without compromising its usage, through a constraint methodology that is inspired from recent neurobiological findings. We further develop a computational model, consisting of several brain areas related to hand control, using a co-evolutionary architecture. Due to its neurobiological basis the methodology gives rise to a number of emergent properties that have been shown to occur in primate species during reach-to-grasp tasks.</td>
</tr>
<tr id="bib_Hourdakis2007" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hourdakis2007,
  author = {Hourdakis, Emmanouil and Maniadakis, Michail and Trahanias, Panos},
  title = {A biologically inspired approach for the control of the hand},
  journal = {2007 IEEE Congress on Evolutionary Computation},
  publisher = {Ieee},
  year = {2007},
  pages = {1503--1510},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4424650},
  doi = {http://dx.doi.org/10.1109/CEC.2007.4424650}
}
</pre></td>
</tr>
<tr id="Krichmar2011" class="entry">
	<td>Krichmar, J. and Wagatsuma, H.</td>
	<td>Neuromorphic and Brain-Based Robots <p class="infolinks">[<a href="javascript:toggleInfo('Krichmar2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Krichmar2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1017/CBO9780511994838">DOI</a> <a href="http://ebooks.cambridge.org/ref/id/CBO9780511994838">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Krichmar2011" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Neuromorphic and brain-based robotics have enormous potential for furthering our understanding of the brain. By embodying models of the brain on robotic platforms, researchers can investigate the roots of biological intelligence and work towards the development of truly intelligent machines. This paper discusses the history of the field and its potential. We give examples of biologically inspired robot designs and neural architectures that lead to brain-based robots. Looking to the future, we consider the development of cognitive, or even conscious, robots that display the adaptability and intelligence of biological organisms.</td>
</tr>
<tr id="bib_Krichmar2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Krichmar2011,
  author = {Krichmar, Jeffrey and Wagatsuma, Hiroaki},
  title = {Neuromorphic and Brain-Based Robots},
  publisher = {Cambridge University Press},
  year = {2011},
  url = {http://ebooks.cambridge.org/ref/id/CBO9780511994838},
  doi = {http://dx.doi.org/10.1017/CBO9780511994838}
}
</pre></td>
</tr>
<tr id="Kurup2012" class="entry">
	<td>Kurup, U. and Lebiere, C.</td>
	<td>What can cognitive architectures do for robotics? <p class="infolinks">[<a href="javascript:toggleInfo('Kurup2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kurup2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Biologically Inspired Cognitive Architectures<br/>Vol. 2, pp. 88-99&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.bica.2012.07.004">DOI</a> <a href="http://linkinghub.elsevier.com/retrieve/pii/S2212683X12000333">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Kurup2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Research in robotic systems has traditionally been identified with approaches that are charac- terized by the use of carefully crafted representations and processes to find optimal solutions. The use of such representations and processes, which we refer to as the algorithmic approach, is uniquely suited for problems requiring strong models, i.e., tasks and domains that are well defined, and/or involve close interaction with the environment. These problems have histori- cally been the focus of robotics research because they exercise perceptual, motor and manip- ulation capabilities that form the basic foundational abilities required for every robotic agent. Recent work (for example ROS and Tekkotsu) on the abstraction and encapsulation of percep- tion and motor functionality has standardized the above mentioned foundational abilities and allowed researchers to study problems in less clearly defined and open-ended domains: prob- lems that have previously been considered the province of AI and Cognitive Science. In this paper, we argue that the study of these problems (examples of which include multi-agent inter- action, instruction following and reasoning in complex domains) referred to under the rubric of Cognitive Robotics is best achieved via the use of cognitive architectures – unified computa- tional frameworks developed specifically for general problem solving and human cognitive mod- eling. We lay out the relevant architectural concepts and principles and illustrate them using nine cognitive architectures that are under active development - Soar, ACT-R, CLARION, GMU-BICA, Polyscheme, Co-JACK, ADAPT, ACT-R/E, and SS-RICS.</td>
</tr>
<tr id="bib_Kurup2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Kurup2012,
  author = {Kurup, Unmesh and Lebiere, Christian},
  title = {What can cognitive architectures do for robotics?},
  journal = {Biologically Inspired Cognitive Architectures},
  publisher = {Elsevier B.V.},
  year = {2012},
  volume = {2},
  pages = {88--99},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X12000333},
  doi = {http://dx.doi.org/10.1016/j.bica.2012.07.004}
}
</pre></td>
</tr>
<tr id="Lipinski2012" class="entry">
	<td>Lipinski, J., Schneegans, S., Sandamirskaya, Y., Spencer, J.P. and Sch&ouml;ner, G.</td>
	<td>A neurobehavioral model of flexible spatial language behaviors. <p class="infolinks">[<a href="javascript:toggleInfo('Lipinski2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Lipinski2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Journal of experimental psychology. Learning, memory, and cognition<br/>Vol. 38(6), pp. 1490-511&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1037/a0022643">DOI</a> <a href="http://www.ncbi.nlm.nih.gov/pubmed/21517224">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Lipinski2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: We propose a neural dynamic model that specifies how low-level visual processes can be integrated with higher level cognition to achieve flexible spatial language behaviors. This model uses real-word visual input that is linked to relational spatial descriptions through a neural mechanism for reference frame transformations. We demonstrate that the system can extract spatial relations from visual scenes, select items based on relational spatial descriptions, and perform reference object selection in a single unified architecture. We further show that the performance of the system is consistent with behavioral data in humans by simulating results from 2 independent empirical studies, 1 spatial term rating task and 1 study of reference object selection behavior. The architecture we present thereby achieves a high degree of task flexibility under realistic stimulus conditions. At the same time, it also provides a detailed neural grounding for complex behavioral and cognitive processes.</td>
</tr>
<tr id="bib_Lipinski2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Lipinski2012,
  author = {Lipinski, John and Schneegans, Sebastian and Sandamirskaya, Yulia and Spencer, John P and Sch&ouml;ner, Gregor},
  title = {A neurobehavioral model of flexible spatial language behaviors.},
  journal = {Journal of experimental psychology. Learning, memory, and cognition},
  year = {2012},
  volume = {38},
  number = {6},
  pages = {1490--511},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/21517224},
  doi = {http://dx.doi.org/10.1037/a0022643}
}
</pre></td>
</tr>
<tr id="Liu2003" class="entry">
	<td>Liu, Y.L.Y. and Thrun, S.</td>
	<td>Results for outdoor-SLAM using sparse extended information filters <p class="infolinks">[<a href="javascript:toggleInfo('Liu2003','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Liu2003','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td><br/>Vol. 12003 IEEE International Conference on Robotics and Automation Cat No03CH37422, pp. 1227-1233&nbsp;</td>
	<td>misc</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2003.1241760">DOI</a> <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1241760">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Liu2003" class="abstract show">
	<td colspan="6"><b>Abstract</b>: In Thrun, S., et al., 2001, we proposed the sparse extended information filter for efficiently solving the simultaneous localization and mapping (SLAM) problem. In this paper, we extend this algorithm to handle data association problems and report real-world results, obtained with an outdoor vehicle. We find that our approach performs favorably when compared to the extended Kalman filter solution from which it is derived.</td>
</tr>
<tr id="bib_Liu2003" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Liu2003,
  author = {Liu, Yufeng Liu Yufeng and Thrun, S},
  title = {Results for outdoor-SLAM using sparse extended information filters},
  booktitle = {2003 IEEE International Conference on Robotics and Automation Cat No03CH37422},
  publisher = {Ieee},
  year = {2003},
  volume = {1},
  pages = {1227--1233},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1241760},
  doi = {http://dx.doi.org/10.1109/ROBOT.2003.1241760}
}
</pre></td>
</tr>
<tr id="Maddern2012" class="entry">
	<td>Maddern, W., Milford, M. and Wyeth, G.</td>
	<td>CAT-SLAM: probabilistic localisation and mapping using a continuous appearance-based trajectory <p class="infolinks">[<a href="javascript:toggleInfo('Maddern2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Maddern2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>The International Journal of Robotics Research<br/>Vol. 31(4), pp. 429-451&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1177/0278364912438273">DOI</a> <a href="http://ijr.sagepub.com/cgi/doi/10.1177/0278364912438273">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Maddern2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: This paper describes a new system, dubbed Continuous Appearance-based Trajectory Simultaneous Localisation and Mapping (CAT-SLAM), which augments sequential appearance-based place recognition with local metric pose filtering to improve the frequency and reliability of appearance-based loop closure. As in other approaches to appearance-based mapping, loop closure is performed without calculating global feature geometry or performing 3D map construction. Loop-closure filtering uses a probabilistic distribution of possible loop closures along the robot’s previous trajectory,which is represented by a linked list of previously visited locations linked by odometric information. Sequential appearance-based place recognition and local metric pose filtering are evaluated simultaneously using a Rao–Blackwellised particle filter, which weights particles based on appearance matching over sequential frames and the similarity of robot motion along the trajectory. The particle filter explicitly models both the likelihood of revisiting previous locations and exploring new locations. A modified resampling scheme counters particle deprivation and allows loop-closure updates to be performed in constant time for a given environment. We compare the performance of CAT-SLAM with FAB-MAP (a state-of-the-art appearance-only SLAM algorithm) using multiple real-world datasets, demonstrating an increase in the number of correct loop closures detected by CAT-SLAM.</td>
</tr>
<tr id="bib_Maddern2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Maddern2012,
  author = {Maddern, W. and Milford, M. and Wyeth, G.},
  title = {CAT-SLAM: probabilistic localisation and mapping using a continuous appearance-based trajectory},
  journal = {The International Journal of Robotics Research},
  year = {2012},
  volume = {31},
  number = {4},
  pages = {429--451},
  url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364912438273},
  doi = {http://dx.doi.org/10.1177/0278364912438273}
}
</pre></td>
</tr>
<tr id="Milford2007" class="entry">
	<td>Milford, M., Schulz, R., Prasser, D., Wyeth, G. and Wiles, J.</td>
	<td>Learning spatial concepts from RatSLAM representations <p class="infolinks">[<a href="javascript:toggleInfo('Milford2007','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Milford2007','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 55(5), pp. 403-410&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2006.12.006">DOI</a> <a href="http://linkinghub.elsevier.com/retrieve/pii/S0921889006002041">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Milford2007" class="abstract show">
	<td colspan="6"><b>Abstract</b>: RatSLAM is a biologically-inspired visual SLAM and navigation system that has been shown to be effective indoors and outdoors on real robots. The spatial representation at the core of RatSLAM, the experience map, forms in a distributed fashion as the robot learns the environment. The activity in RatSLAM’s experience map possesses some geometric properties, but still does not represent the world in a human readable form. A new system, dubbed RatChat, has been introduced to enable meaningful communication with the robot. The intention is to use the “language games” paradigm to build spatial concepts that can be used as the basis for communication. This paper describes the first step in the language game experiments, showing the potential for meaningful categorization of the spatial representations in RatSLAM.</td>
</tr>
<tr id="bib_Milford2007" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Milford2007,
  author = {Milford, Michael and Schulz, Ruth and Prasser, David and Wyeth, Gordon and Wiles, Janet},
  title = {Learning spatial concepts from RatSLAM representations},
  journal = {Robotics and Autonomous Systems},
  year = {2007},
  volume = {55},
  number = {5},
  pages = {403--410},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889006002041},
  doi = {http://dx.doi.org/10.1016/j.robot.2006.12.006}
}
</pre></td>
</tr>
<tr id="Milford2004" class="entry">
	<td>Milford, M., Wyeth, G. and Prasser, D.</td>
	<td>RatSLAM: a hippocampal model for simultaneous localization and mapping <p class="infolinks">[<a href="javascript:toggleInfo('Milford2004','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Milford2004','bibtex')">BibTeX</a>]</p></td>
	<td>2004</td>
	<td>Robotics and Automation, ldots(May 2004), pp. 403-408&nbsp;</td>
	<td>article</td>
	<td><a href="http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1307183">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Milford2004" class="abstract show">
	<td colspan="6"><b>Abstract</b>: The paper presents a new approach to the problem of Simultaneous Localization and Mapping - SLAM - inspired by computational models of the hippocampus of rodents. The rodents hippocampus has been extensively studied with respect to navigation tasks, and displays many of the properties of a desirable SLAM solution. RatSLAM is an implementation of a hippocampal model that can perform SLAM in real time on a real robot. It uses competitive attractor network to integrate odometric information with landmark sensing to form a consistent representation of the environment. Experimental results show that RatSLAM can operate with ambiguous landmark information and recover from both minor and major path integration errors.</td>
</tr>
<tr id="bib_Milford2004" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Milford2004,
  author = {Milford, MJ and Wyeth, GF and Prasser, D},
  title = {RatSLAM: a hippocampal model for simultaneous localization and mapping},
  journal = {Robotics and Automation, ldots},
  year = {2004},
  number = {May 2004},
  pages = {403--408},
  url = {http://ieeexplore.ieee.org/xpls/absall.jsp?arnumber=1307183}
}
</pre></td>
</tr>
<tr id="Morse2011" class="entry">
	<td>Morse, A.F., Herrera, C., Clowes, R., Montebelli, A. and Ziemke, T.</td>
	<td>The role of robotic modelling in cognitive science <p class="infolinks">[<a href="javascript:toggleInfo('Morse2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Morse2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>New Ideas in Psychology<br/>Vol. 29(3), pp. 312-324&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.newideapsych.2011.02.001">DOI</a> <a href="http://linkinghub.elsevier.com/retrieve/pii/S0732118X11000109">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Morse2011" class="abstract show">
	<td colspan="6"><b>Abstract</b>: From the perspective of cognitive robotics, this paper presents a modern interpretation of Newell’s (1973) reasoning and suggestions for why and how cognitive psychologists should develop models of cognitive phenomena. We argue that the shortcomings of current cognitive modelling approaches are due in significant part to a lack of exactly the kind of integration required for the development of embodied autonomous robotics. Moreover we suggest that considerations of embodiment, situatedness, and autonomy, intrinsic to cognitive robotics, provide an appropriate basis for the integration and theoretic cumulation that Newell argued was necessary for psychology to mature. From this perspective we analyse the role of embodiment and modes of situatedness in terms of integration, cognition, emotion, and autonomy. Four complementary perspectives on embodied and situated cognitive science are considered in terms of their poten- tial to contribute to cognitive robotics, cognitive science, and psychological theorizing: minimal cognition and organization, enactive perception and sensorimotor contingency, homeostasis and emotion, and social embedding. In combination these perspectives provide a framework for cognitive robotics, not only wholly compatible with the original aims of cognitive modelling, but as a more appropriate methodology than those currently in common use within psychology.</td>
</tr>
<tr id="bib_Morse2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Morse2011,
  author = {Morse, Anthony F. and Herrera, Carlos and Clowes, Robert and Montebelli, Alberto and Ziemke, Tom},
  title = {The role of robotic modelling in cognitive science},
  journal = {New Ideas in Psychology},
  publisher = {Elsevier Ltd},
  year = {2011},
  volume = {29},
  number = {3},
  pages = {312--324},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0732118X11000109},
  doi = {http://dx.doi.org/10.1016/j.newideapsych.2011.02.001}
}
</pre></td>
</tr>
<tr id="Newell1992" class="entry">
	<td>Newell, A.</td>
	<td>Precis of `Unified Theories of Cognition' <p class="infolinks">[<a href="javascript:toggleInfo('Newell1992','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Newell1992','bibtex')">BibTeX</a>]</p></td>
	<td>1992</td>
	<td>Behavioral and Brain Sciences<br/>Vol. 15(3), pp. 425-492&nbsp;</td>
	<td>article</td>
	<td><a href="http://journals.cambridge.org/abstract\_S0140525X00069478">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Newell1992" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Summarizes the book Unified Theories of Cognition (A. Newell, 1990) and asserts that unifying theories of cognition is a worthy goal. An exemplar candidate is put forth to illustrate concretely what a unified theory of cognition means and why it should be a goal for cognitive science. The candidate is a theory (and system) called SOAR (J. E. Laird et al, 1987). The book is the written version of the William James Lectures, delivered at Harvard University in Spring 1987. Discussed are foundations of cognitive science; human cognitive architecture; symbolic processing for intelligence; immediate behavior; and memory, learning, and skill. 26 comments follow, and the author responds. (PsycINFO Database Record (c) 2003 APA</td>
</tr>
<tr id="bib_Newell1992" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Newell1992,
  author = {Newell, Allen},
  title = {Precis of `Unified Theories of Cognition'},
  journal = {Behavioral and Brain Sciences},
  year = {1992},
  volume = {15},
  number = {3},
  pages = {425--492},
  url = {http://journals.cambridge.org/abstractS0140525X00069478}
}
</pre></td>
</tr>
<tr id="Pfeifer2007" class="entry">
	<td>Pfeifer, R.</td>
	<td>Biologically Inspired Robotics <p class="infolinks">[<a href="javascript:toggleInfo('Pfeifer2007','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pfeifer2007','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>Science<br/>Vol. 1088(2007), pp. 1088-93&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1126/science.1145803">DOI</a> <a href="http://www.scholarpedia.org/article/Biologically\_inspired\_robotics">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pfeifer2007" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Robotics researchers increasingly agree that ideas from biology and self-organization can strongly benefit the design of autonomous robots. Biological organisms have evolved to perform and survive in a world characterized by rapid changes, high uncertainty, indefinite richness, and limited availability of information. Industrial robots, in contrast, operate in highly controlled environments with no or very little uncertainty. Although many challenges remain, concepts from biologically inspired (bio-inspired) robotics will eventually enable researchers to engineer machines for the real world that possess at least some of the desirable properties of biological organisms, such as adaptivity, robustness, versatility, and agility.</td>
</tr>
<tr id="bib_Pfeifer2007" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Pfeifer2007,
  author = {Pfeifer, Rolf},
  title = {Biologically Inspired Robotics},
  journal = {Science},
  publisher = {Oxford University Press},
  year = {2007},
  volume = {1088},
  number = {2007},
  pages = {1088--93},
  url = {http://www.scholarpedia.org/article/Biologicallyinspiredrobotics},
  doi = {http://dx.doi.org/10.1126/science.1145803}
}
</pre></td>
</tr>
<tr id="SandamirskayaROMAN2010" class="entry">
	<td>Sandamirskaya, Y. and Lipinski, J.</td>
	<td>Natural human-robot interaction through spatial language: a Dynamic Neural Field approach <p class="infolinks">[<a href="javascript:toggleInfo('SandamirskayaROMAN2010','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('SandamirskayaROMAN2010','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>RO-MAN, 2010 ldots&nbsp;</td>
	<td>article</td>
	<td><a href="http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5598671">URL</a>&nbsp;</td>
</tr>
<tr id="abs_SandamirskayaROMAN2010" class="abstract show">
	<td colspan="6"><b>Abstract</b>: For an autonomous robotic system, the ability to share the same workspace and interact with humans is the basis for cooperative behavior. In this work, we investigate human spatial language as the communicative channel between the robot and the human, facilitating their joint work on a tabletop. We specifically combine the theory of Dynamic Neural Fields that represent perceptual and cognitive states with motor control and linguistic input in a robotic demonstration. We show that such a neural dynamic framework can integrate across symbolic, perceptual, and motor processes to generate task-specific spatial communication in real time.</td>
</tr>
<tr id="bib_SandamirskayaROMAN2010" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{SandamirskayaROMAN2010,
  author = {Sandamirskaya, Yulia and Lipinski, John},
  title = {Natural human-robot interaction through spatial language: a Dynamic Neural Field approach},
  journal = {RO-MAN, 2010 ldots},
  year = {2010},
  url = {http://ieeexplore.ieee.org/xpls/absall.jsp?arnumber=5598671}
}
</pre></td>
</tr>
<tr id="Sandamirskaya2011" class="entry">
	<td>Sandamirskaya, Y., Richter, M. and Sch&ouml;ner, G.</td>
	<td>A neural-dynamic architecture for behavioral organization of an embodied agent <p class="infolinks">[<a href="javascript:toggleInfo('Sandamirskaya2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Sandamirskaya2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>ldots and Learning (ICDL), ldots&nbsp;</td>
	<td>article</td>
	<td><a href="http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6037353">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Sandamirskaya2011" class="abstract show">
	<td colspan="6"><b>Abstract</b>: How agents generate meaningful sequences of ac- tions in natural environments is one of the most challenging problems in studies of natural cognition and in the design of artificial cognitive systems. Each action in a sequence must contribute to the behavioral objective, while at the same time satisfying constraints that arise from the environment, the agent’s embodiment, and the agent’s behavioral history. In this paper, we introduce a neural-dynamic architecture that enables selection of an appropriate action for a given task in a particular environment and is open to learning. We use the same framework of neural dynamics for all processes from perception, to representation and motor planning as well as behavioral organization. This facilitates integration and flexibility. The neural dynamic representations of particular behaviors emerge on the fly from the interplay between task and environment inputs as well as behavioral history. All behavioral states are attractors of the neural dynamics, whose instabilities lead to behavioral switches. As a result, behavioral organization is robust in the face of noisy and unreliable sensory information.</td>
</tr>
<tr id="bib_Sandamirskaya2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Sandamirskaya2011,
  author = {Sandamirskaya, Yulia and Richter, Mathis and Sch&ouml;ner, Gregor},
  title = {A neural-dynamic architecture for behavioral organization of an embodied agent},
  journal = {ldots and Learning (ICDL), ldots},
  year = {2011},
  url = {http://ieeexplore.ieee.org/xpls/absall.jsp?arnumber=6037353}
}
</pre></td>
</tr>
<tr id="Spencer2012" class="entry">
	<td>Spencer, J.P., Austin, A. and Schutte, A.R.</td>
	<td>Contributions of dynamic systems theory to cognitive development <p class="infolinks">[<a href="javascript:toggleInfo('Spencer2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Spencer2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Cognitive Development<br/>Vol. 27(4), pp. 401-418&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.cogdev.2012.07.006">DOI</a> <a href="http://linkinghub.elsevier.com/retrieve/pii/S0885201412000457">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Spencer2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: We examine the contributions of dynamic systems theory to the field of cognitive development, focusing on modeling using dynamic neural fields. After introducing central concepts of dynamic field theory (DFT), we probe empirical predictions and findings around two examples—the DFT of infant perseverative reaching that explains Piaget’s A-not-B error and the DFT of spatial memory that explain changes in spatial cognition in early develop- ment. Review of the literature around these examples reveals that computational modeling is having an impact on empirical research in cognitive development; however, this impact does not extend to neural and clinical research. Moreover, there is a tendency for researchers to interpret models narrowly, anchoring them to spe- cific tasks. We conclude on an optimistic note, encouraging both theoreticians and experimentalists to work toward a more theory- driven future.</td>
</tr>
<tr id="bib_Spencer2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Spencer2012,
  author = {Spencer, John P. and Austin, Andrew and Schutte, Anne R.},
  title = {Contributions of dynamic systems theory to cognitive development},
  journal = {Cognitive Development},
  publisher = {Elsevier Inc.},
  year = {2012},
  volume = {27},
  number = {4},
  pages = {401--418},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0885201412000457},
  doi = {http://dx.doi.org/10.1016/j.cogdev.2012.07.006}
}
</pre></td>
</tr>
<tr id="Strauss2012" class="entry">
	<td>Strauss, S. and Heinke, D.</td>
	<td>A robotics-based approach to modeling of choice reaching experiments on visual attention. <p class="infolinks">[<a href="javascript:toggleInfo('Strauss2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Strauss2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Frontiers in psychology<br/>Vol. 3(April), pp. 105&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.3389/fpsyg.2012.00105">DOI</a> <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3328079\&tool=pmcentrez\&rendertype=abstract">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Strauss2012" class="abstract show">
	<td colspan="6"><b>Abstract</b>: The paper presents a robotics-based model for choice reaching experiments on visual attention. In these experiments participants were asked to make rapid reach movements toward a target in an odd-color search task, i.e., reaching for a green square among red squares and vice versa (e.g., Song and Nakayama, 2008). Interestingly these studies found that in a high number of trials movements were initially directed toward a distractor and only later were adjusted toward the target. These "curved" trajectories occurred particularly frequently when the target in the directly preceding trial had a different color (priming effect). Our model is embedded in a closed-loop control of a LEGO robot arm aiming to mimic these reach movements. The model is based on our earlier work which suggests that target selection in visual search is implemented through parallel interactions between competitive and cooperative processes in the brain (Heinke and Humphreys, 2003; Heinke and Backhaus, 2011). To link this model with the control of the robot arm we implemented a topological representation of movement parameters following the dynamic field theory (Erlhagen and Schoener, 2002). The robot arm is able to mimic the results of the odd-color search task including the priming effect and also generates human-like trajectories with a bell-shaped velocity profile. Theoretical implications and predictions are discussed in the paper.</td>
</tr>
<tr id="bib_Strauss2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Strauss2012,
  author = {Strauss, Soeren and Heinke, Dietmar},
  title = {A robotics-based approach to modeling of choice reaching experiments on visual attention.},
  journal = {Frontiers in psychology},
  year = {2012},
  volume = {3},
  number = {April},
  pages = {105},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3328079&amp;tool=pmcentrez&amp;rendertype=abstract},
  doi = {http://dx.doi.org/10.3389/fpsyg.2012.00105}
}
</pre></td>
</tr>
<tr id="Taylor1999" class="entry">
	<td>Taylor, J.G.</td>
	<td>Neural 'bubble' dynamics in two dimensions: foundations <p class="infolinks">[<a href="javascript:toggleInfo('Taylor1999','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Taylor1999','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td>Biological Cybernetics<br/>Vol. 80, pp. 393-409&nbsp;</td>
	<td>article</td>
	<td><a href="http://link.springer.com/content/pdf/10.1007\%2Fs004220050534.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Taylor1999" class="abstract show">
	<td colspan="6"><b>Abstract</b>: An extension to two dimensions of recent results in continuum neural field theory (CNFT) in one dimension is presented here. Focus is placed on the treatment of receptive fields and of learning on aerent synapses to obtain topographic maps.</td>
</tr>
<tr id="bib_Taylor1999" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Taylor1999,
  author = {Taylor, J G},
  title = {Neural 'bubble' dynamics in two dimensions: foundations},
  journal = {Biological Cybernetics},
  year = {1999},
  volume = {80},
  pages = {393--409},
  url = {http://link.springer.com/content/pdf/10.1007Fs004220050534.pdf}
}
</pre></td>
</tr>
<tr id="Thrun2010" class="entry">
	<td>Thrun, S.</td>
	<td>Toward robotic cars <p class="infolinks">[<a href="javascript:toggleInfo('Thrun2010','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Thrun2010','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>Communications of the ACM<br/>Vol. 53(4), pp. 99-106&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1145/1721654.1721679">DOI</a> <a href="http://portal.acm.org/citation.cfm?doid=1721654.1721679">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Thrun2010" class="abstract show">
	<td colspan="6"><b>Abstract</b>: This article advocates self-driving, robotic technology for cars. Recent challenges organized by DARPA have induced a significant advance in technology for autopilots for cars; similar to those already used in aircraft and marine vessels. This article reviews this technology, and argues that enormous societal benefits can be reaped by deploying this emerging technology in the marketplace. It lays out a vision for deployment, and discusses some of the key remaining technology obstacles.</td>
</tr>
<tr id="bib_Thrun2010" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Thrun2010,
  author = {Thrun, Sebastian},
  title = {Toward robotic cars},
  journal = {Communications of the ACM},
  publisher = {ACM},
  year = {2010},
  volume = {53},
  number = {4},
  pages = {99--106},
  url = {http://portal.acm.org/citation.cfm?doid=1721654.1721679},
  doi = {http://dx.doi.org/10.1145/1721654.1721679}
}
</pre></td>
</tr>
<tr id="Wyeth2009" class="entry">
	<td>Wyeth, G. and Milford, M.</td>
	<td>Spatial cognition for robots <p class="infolinks">[<a href="javascript:toggleInfo('Wyeth2009','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Wyeth2009','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td><br/>Vol. 16(3)IEEE Robotics Automation Magazine, pp. 24-32&nbsp;</td>
	<td>misc</td>
	<td><a href="http://dx.doi.org/10.1109/MRA.2009.933620">DOI</a> <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5233413">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Wyeth2009" class="abstract show">
	<td colspan="6"><b>Abstract</b>: The paper discusses robot navigation from biological inspiration. The authors sought to build a model of the rodent brain that is suitable for practical robot navigation. The core model, dubbed RatSLAM, has been demonstrated to have exactly the same advantages described earlier: it can build, maintain, and use maps simultaneously over extended periods of time and can construct maps of large and complex areas from very weak geometric information. The work contrasts with other efforts to embody models of rat brains in robots. The article describes the key elements of the known biology of the rat brain in relation to navigation and how the RatSLAM model captures the ideas from biology in a fashion suitable for implementation on a robotic platform. The paper then outline RatSLAM's performance in two difficult robot navigation challenges, demonstrating how a cognitive robotics approach to navigation can produce results that rival other state of the art approaches in robotics.</td>
</tr>
<tr id="bib_Wyeth2009" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Wyeth2009,
  author = {Wyeth, G and Milford, M},
  title = {Spatial cognition for robots},
  booktitle = {IEEE Robotics Automation Magazine},
  year = {2009},
  volume = {16},
  number = {3},
  pages = {24--32},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5233413},
  doi = {http://dx.doi.org/10.1109/MRA.2009.933620}
}
</pre></td>
</tr>
<tr id="Wyeth2011" class="entry">
	<td>Wyeth, G., Milford, M., Schulz, R. and Wiles, J.</td>
	<td>The RatSLAM project: robot spatial navigation <p class="infolinks">[<a href="javascript:toggleInfo('Wyeth2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>Neuromorphic and Brain-Based Robots, pp. 87-108&nbsp;</td>
	<td>incollection</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Wyeth2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Wyeth2011,
  author = {Wyeth, Gordon and Milford, Michael and Schulz, Ruth and Wiles, Janet},
  title = {The RatSLAM project: robot spatial navigation},
  booktitle = {Neuromorphic and Brain-Based Robots},
  publisher = {Cambridge University Press},
  year = {2011},
  pages = {87--108}
}
</pre></td>
</tr>
<tr id="Zibner2011" class="entry">
	<td>Zibner, S.K.U., Faubel, C., Iossifidis, I. and Sch&ouml;ner, G.</td>
	<td>Dynamic Neural Fields as Building Blocks of a Cortex-Inspired Architecture for Robotic Scene Representation <p class="infolinks">[<a href="javascript:toggleInfo('Zibner2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Zibner2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>IEEE Transactons on Autonomous Mental Development<br/>Vol. 3(1), pp. 74-91&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Zibner2011" class="abstract show">
	<td colspan="6"><b>Abstract</b>: Based on the concepts of dynamic field theory (DFT), we present an architecture that autonomously generates scene representations by controlling gaze and attention, creating visual objects in the foreground, tracking objects, reading them into working memory, and taking into account their visibility. At the core of this architecture are three-dimensional dynamic neural fields (DNFs) that link feature to spatial information. These three-dimensional fields couple into lower dimensional fields, which provide the links to the sensory surface and to the motor systems.We discuss how DNFs can be used as building blocks for cognitive architectures, characterize the critical bifurcations in DNFs, as well as the possible coupling structures among DNFs. In a series of robotic experiments, we demonstrate how the DNF architecture provides the core functionalities of a scene representation.</td>
</tr>
<tr id="bib_Zibner2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Zibner2011,
  author = {Zibner, Stephan K U and Faubel, Christian and Iossifidis, Ioannis and Sch&ouml;ner, Gregor},
  title = {Dynamic Neural Fields as Building Blocks of a Cortex-Inspired Architecture for Robotic Scene Representation},
  journal = {IEEE Transactons on Autonomous Mental Development},
  year = {2011},
  volume = {3},
  number = {1},
  pages = {74--91}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 08/06/2013.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>